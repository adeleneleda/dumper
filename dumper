#!/usr/bin/python

import subprocess
import time
import os
import boto
import argparse

from boto.s3.connection import S3Connection
from boto.s3.key import Key
from time import strftime


BACKUP_PATH='/tmp/dumper-backups/'

'''

./dumper -a BACKUP -d sparks1  -b 'atp-backups' --aws_key_id=`echo $ATP_AWS_ACCESS_KEY_ID`

./dumper -a RESTORE -d sparks1 -f 'atp_test2015-12-04-13-12-18.sql'  -b 'atp-backups' --aws_key_id=`echo $ATP_AWS_ACCESS_KEY_ID`

'''

def prepare_dir(dir_name):
  if not os.path.exists(dir_name):
      print "[+] Creating directory: %s" % dir_name
      os.makedirs(dir_name)

def establish_connection(access_key, secret_key, bucket_name):
  if access_key is None:
    access_key = os.environ['ATP_AWS_ACCESS_KEY_ID'].strip()
  if secret_key is None:
    secret_key = os.environ['ATP_AWS_SECRET_ACCESS_KEY'].strip()

  conn = S3Connection(access_key, secret_key)
  bucket = conn.get_bucket(bucket_name)

  return bucket


def main():
  parser = argparse.ArgumentParser(prog='dumper',
                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)


  parser.add_argument('-a', '--action', nargs='?', type=str, default='BACKUP', help='Allowed values: BACKUP or RESTORE')
  parser.add_argument('-s', '--host', nargs='?', type=str, default='localhost', help='host')
  parser.add_argument('-u', '--user', nargs='?', type=str, default='postgres', help='username')
  parser.add_argument('-p', '--password', nargs='?', type=str, default='', help='password')
  parser.add_argument('-d', '--database', nargs='?', type=str, help='database')
  parser.add_argument('-f', '--filename', nargs='?', type=str, help='filename')
  parser.add_argument('-t', '--path', nargs='?', type=str, help='Destination path for backup file')
  parser.add_argument('-b', '--bucket', nargs='?', type=str, help='AWS Bucket Name', required=True)

  parser.add_argument('--aws_key_id', nargs='?', type=str, help='AWS Access Key ID')
  parser.add_argument('--aws_secret_key', nargs='?', type=str, help='AWS Secret Access Key')

  args = parser.parse_args()
  print args

  # set_env_vars()
  bucket = establish_connection(args.aws_key_id, args.aws_secret_key, args.bucket)


  if args.action == "FILES":
    show_keys(bucket)

  elif args.action == "BACKUP" and args.database is not None:
    print "BACKING UP"
    dump_and_upload_to_s3(bucket, args.database, args.user)


  elif args.action == "RESTORE" and args.database is not None and args.filename is not None:
    print "RESTORE"
    download_and_restore_from_s3(bucket, args.filename, args.database, args.path)
    # ADD CHECK IF DB ALREADY EXISTS

  else:
    parser.print_help()

def dump_and_upload_to_s3(bucket, database, user):
  location = BACKUP_PATH + "upload"
  prepare_dir(location)

  filename = database + "-" + time.strftime("%Y-%m-%d-%H-%M-%S") + ".sql"

  dump_database(database, user, location + filename)
  upload_to_s3(bucket, location + filename, filename)

def download_and_restore_from_s3(bucket, filename, database, destination):
  prepare_dir(BACKUP_PATH)

  if destination is None:
    destination = BACKUP_PATH + filename

  download_from_s3(bucket, filename, destination)
  restore_database(filename, database, destination)


def dump_database(database, user, path):
  ps = subprocess.Popen(
        ['pg_dump', '-U', user, '-Fc', database, '-f', path],
        stdout=subprocess.PIPE
    )
  output = ps.communicate()[0]

def upload_to_s3(bucket, path, filename):
  k = Key(bucket)
  k.key = filename
  k.set_contents_from_filename(path)

def download_from_s3(bucket, filename, destination):
  key = bucket.get_key(filename)
  key.get_contents_to_filename(destination)

def restore_database(filename, database, destination):
  print "createdb -U postgres " + database

  subprocess.call("createdb -U postgres " + database, shell=True)

  print "pg_restore --verbose --clean --no-acl --no-owner -h localhost -U postgres -d " + database + " " +  destination

  subprocess.call("pg_restore --verbose --clean --no-acl --no-owner -h localhost -U postgres -d " + database + " " +  destination, shell=True)

def show_keys(bucket):
  for key in bucket.list():
    print key.name.encode('utf-8')

if __name__ == '__main__':
  main()